#! /usr/bin/env python3

import requests, os
from bs4 import BeautifulSoup

BASE = "/home/david/master/"

uni_link = "https://www.physik.uni-muenchen.de/lehre/vorlesungen/wise_19_20/"

vls = {
        "IFT/Tutorial":   "https://wwwmpa.mpa-garching.mpg.de/~ensslin/lectures/lectures.html"
}

def extras(name, link):
    if name == "TCMP/Tutorial":
        if "Sol" in link[1]:
            name = "TCMP/Solution"
    elif name == "TCMP/Lecture":
        f = os.path.join(BASE, name)
        lecs = [x for x in os.listdir(f) if x[:3] == "lec"]
        lecs = " ".join(map(lambda x: os.path.join(f, x), 
            sorted(lecs, key=lambda x: int(x[3:-4]))))
        os.system("pdftk {} cat output {}TCMP/lecture1.pdf".format(lecs, BASE))
        os.system("pdftk {0}TCMP/lecture1.pdf dump_data output {0}TCMP/meta.txt".format(BASE))
        os.system("pdftotext {0}/TCMP/lecture1.pdf".format(BASE))
        chaps = {}
        with open("{}TCMP/lecture1.txt".format(BASE), "r") as f:
            for line in f:
                if "Seite" in line:
                    x = line.replace("Seite", "#").split("#")[0].strip()
                    if x in chaps:
                        chaps[x] += 1
                    else:
                        chaps[x] = 1
        with open("{}TCMP/meta.txt".format(BASE), "a") as f:
            p = 1
            for chap, page in chaps.items():
                f.write("BookmarkBegin\nBookmarkTitle: {}\nBookmarkLevel: 1\nBookmarkPageNumber: {}\n".format(chap, p))
                p += page
        os.system("pdftk {0}TCMP/lecture1.pdf update_info {0}TCMP/meta.txt output {0}TCMP/lecture.pdf".format(BASE))
        os.remove("{}TCMP/lecture1.pdf".format(BASE))
        os.remove("{}TCMP/meta.txt".format(BASE))
        os.remove("{}/TCMP/lecture1.txt".format(BASE))
    return name.replace("/", " ")

def base_link(link):
    while(link[-1] != "/"):
        link = link[:-1]
    return link

def contents(vl, soup):
    if(vl=="IFT/Tutorial"):
         return soup.find("section", {"id": "Tutorials"})
    return soup.find("div", {"id": "contentcontainer"})

pdf_links = {}

for vl, link in vls.items():
    soup = BeautifulSoup(requests.get(link).content, features="lxml")
    bl = base_link(link)
    contentarea = contents(vl, soup)
    links = contentarea.findAll("a")
    pdf_links[vl] = []
    for l in links:
        if l["href"][-3:] == "pdf":
            x = l["href"]
            if "/" in x:
                i = x.find("/")
                bl_2 = bl + x[:i+1]
                x = x[i+1:]
            else:
                bl_2 = bl
            pdf_links[vl] += [(bl_2, x)]

for name, links in pdf_links.items():
    os.makedirs(BASE+name, exist_ok=True)
    for link in links:
        f = os.path.join(BASE+name, link[1])
        if not os.path.isfile(f):
            os.system('wget -q --output-document="{}" --user={} --password={} {}'.format(
                f, "David.Bucher", "wakeman1", link[0]+link[1]))
            name1 = extras(name, links)
            os.system('notify-send --urgency=normal "New {}!" "{} downloaded."'.format(name1, link[1]))
